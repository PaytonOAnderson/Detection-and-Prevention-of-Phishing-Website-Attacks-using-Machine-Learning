{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaytonOAnderson/Detection-and-Prevention-of-Phishing-Website-Attacks-using-Machine-Learning/blob/main/Phishing_Detection_429.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/ebubekirbbr/pdd/blob/master/input/data_phishing_37175.json\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the phishing data from the JSON file\n",
        "with open('data_legitimate_36400.json') as f:\n",
        "    ldata = json.load(f)\n",
        "\n",
        "# Load the legitimate data from the JSON file\n",
        "with open('data_phishing_37175.json') as f:\n",
        "    pdata = json.load(f)\n",
        "\n",
        "# Create an empty array to store the combined data\n",
        "combined_data = []\n",
        "\n",
        "# Add the phishing data to the combined data array, and add a label of 1 to indicate that it is phishing\n",
        "for item in pdata:\n",
        "    combined_data.append([item, 1])\n",
        "\n",
        "# Add the legitimate data to the combined data array, and add a label of 0 to indicate that it is legitimate\n",
        "for item in ldata:\n",
        "    combined_data.append([item, 0])\n",
        "\n",
        "# Shuffle the combined data array\n",
        "np.random.shuffle(combined_data)\n",
        "\n",
        "# Convert the combined data array to a numpy array\n",
        "combined_data = np.array(combined_data)\n",
        "\n",
        "print(combined_data[:10])\n",
        "\n"
      ],
      "metadata": {
        "id": "Feq4_FuiTuJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract the links from the combined data\n",
        "links = [item[0] for item in combined_data]\n",
        "\n",
        "# Calculate the percentiles\n",
        "percentiles = np.percentile(np.char.str_len(links), np.arange(0, 101))\n"
      ],
      "metadata": {
        "id": "BYhXFnzGMAEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = []\n",
        "labels = []\n",
        "\n",
        "for item in combined_data:\n",
        "  urls.append(item[0])\n",
        "  labels.append(item[1])\n"
      ],
      "metadata": {
        "id": "mjI0URh8Vsp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Tokenize the URLs\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(urls)\n",
        "sequences = tokenizer.texts_to_sequences(urls)\n",
        "\n",
        "# Pad the sequences\n",
        "max_length = 200\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "# Convert labels to numpy array\n",
        "labels = np.array(labels, dtype=int)"
      ],
      "metadata": {
        "id": "pht2j-T-BTpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Save the padded sequences to a file\n",
        "np.save('padded_sequences.npy', padded_sequences)\n",
        "\n",
        "# Save the labels to a file\n",
        "np.save('labels.npy', labels)\n"
      ],
      "metadata": {
        "id": "hSztZ9dfDkpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base Model"
      ],
      "metadata": {
        "id": "-XUEYkpEkdCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=200, output_dim=128, mask_zero=True),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Compile the model\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history1 = model1.fit(padded_sequences, labels, epochs=10, validation_split=0.2)\n",
        "print(history1.history)"
      ],
      "metadata": {
        "id": "3Q7c3H9yX0Az",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model\n",
        "model1.save('model_1.keras')\n",
        "\n"
      ],
      "metadata": {
        "id": "Yhu5Mzul1O33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the model\n",
        "model1 = tf.keras.models.load_model('model_1.keras')\n"
      ],
      "metadata": {
        "id": "sMii_gGzWhhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history1.history['accuracy']) + 1), history1.history['accuracy'])\n",
        "plt.plot(np.arange(1, len(history1.history['val_accuracy']) + 1), history1.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history1.history['accuracy']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history1.history['loss']) + 1), history1.history['loss'])\n",
        "plt.plot(np.arange(1, len(history1.history['val_loss']) + 1), history1.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history1.history['loss']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Du5CPj1DIrS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions on the test data\n",
        "predictions1 = model1.predict(padded_sequences)\n",
        "\n",
        "# Convert the predictions to binary values\n",
        "for i in range(len(predictions1)):\n",
        "    if predictions1[i] > 0.5:\n",
        "        predictions1[i] = 1\n",
        "    else:\n",
        "        predictions1[i] = 0\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(labels, predictions1)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "sk4fFdnJcjpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the number of true positives, false negatives, true negatives, and false positives.\n",
        "tp = 0\n",
        "fn = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == 1 and predictions1[i] == 1:\n",
        "    tp += 1\n",
        "  elif labels[i] == 1 and predictions1[i] == 0:\n",
        "    fn += 1\n",
        "  elif labels[i] == 0 and predictions1[i] == 0:\n",
        "    tn += 1\n",
        "  elif labels[i] == 0 and predictions1[i] == 1:\n",
        "    fp += 1\n",
        "\n",
        "# Calculate the percentages of true positives, false negatives, true negatives, and false positives.\n",
        "tp_percent = tp / (tp + fn) * 100\n",
        "fn_percent = fn / (tp + fn) * 100\n",
        "tn_percent = tn / (tn + fp) * 100\n",
        "fp_percent = fp / (tn + fp) * 100\n",
        "\n",
        "# Print the percentages of true positives, false negatives, true negatives, and false positives.\n",
        "print(\"True Positives:\", tp_percent)\n",
        "print(\"False Negatives:\", fn_percent)\n",
        "print(\"True Negatives:\", tn_percent)\n",
        "print(\"False Positives:\", fp_percent)\n"
      ],
      "metadata": {
        "id": "Av8M_FVweeLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modifiying the model being created taking out the droupout layers"
      ],
      "metadata": {
        "id": "w6ltixosloTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=200, output_dim=128, mask_zero=True),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dense(128, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(64, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Compile the model\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history2 = model2.fit(padded_sequences, labels, epochs=10, validation_split=0.2)\n",
        "print(history2.history)"
      ],
      "metadata": {
        "id": "CV2D_6Pklns7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model2.save('model_2.keras')\n",
        "# Load the model\n",
        "model2 = tf.keras.models.load_model('model_2.keras')"
      ],
      "metadata": {
        "id": "Js_4ii1ll0tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history2.history['accuracy']) + 1), history2.history['accuracy'])\n",
        "plt.plot(np.arange(1, len(history2.history['val_accuracy']) + 1), history22.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history2.history['accuracy']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history2.history['loss']) + 1), history2.history['loss'])\n",
        "plt.plot(np.arange(1, len(history2.history['val_loss']) + 1), history2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history2.history['loss']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OSXso3gBwqBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions2 = model.predict(padded_sequences)\n",
        "\n",
        "# Convert the predictions to binary values\n",
        "for i in range(len(predictions2)):\n",
        "    if predictions2[i] > 0.5:\n",
        "        predictions2[i] = 1\n",
        "    else:\n",
        "        predictions2[i] = 0\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(labels, predictions2)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "dM3MWHtgw8_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of true positives, false negatives, true negatives, and false positives.\n",
        "tp = 0\n",
        "fn = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == 1 and predictions2[i] == 1:\n",
        "    tp += 1\n",
        "  elif labels[i] == 1 and predictions2[i] == 0:\n",
        "    fn += 1\n",
        "  elif labels[i] == 0 and predictions2[i] == 0:\n",
        "    tn += 1\n",
        "  elif labels[i] == 0 and predictions2[i] == 1:\n",
        "    fp += 1\n",
        "\n",
        "# Calculate the percentages of true positives, false negatives, true negatives, and false positives.\n",
        "tp_percent = tp / (tp + fn) * 100\n",
        "fn_percent = fn / (tp + fn) * 100\n",
        "tn_percent = tn / (tn + fp) * 100\n",
        "fp_percent = fp / (tn + fp) * 100\n",
        "\n",
        "# Print the percentages of true positives, false negatives, true negatives, and false positives.\n",
        "print(\"True Positives:\", tp_percent)\n",
        "print(\"False Negatives:\", fn_percent)\n",
        "print(\"True Negatives:\", tn_percent)\n",
        "print(\"False Positives:\", fp_percent)"
      ],
      "metadata": {
        "id": "gu8_Yz4wxCNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifiying the model being created, removing layer tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))"
      ],
      "metadata": {
        "id": "GrsfqiEQxdRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=200, output_dim=128, mask_zero=True),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Compile the model\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history3 = model3.fit(padded_sequences, labels, epochs=10, validation_split=0.2)\n",
        "print(history3.history)"
      ],
      "metadata": {
        "id": "15RtRwrmxcz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model3.save('model_3.keras')\n",
        "# Load the model\n",
        "model3 = tf.keras.models.load_model('model_3.keras')\n",
        "# Plot accuracy\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history3.history['accuracy']) + 1), history3.history['accuracy'])\n",
        "plt.plot(np.arange(1, len(history3.history['val_accuracy']) + 1), history3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history3.history['accuracy']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history3.history['loss']) + 1), history3.history['loss'])\n",
        "plt.plot(np.arange(1, len(history3.history['val_loss']) + 1), history3.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history3.history['loss']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lIPw92zCyu9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions3 = model.predict(padded_sequences)\n",
        "\n",
        "# Convert the predictions to binary values\n",
        "for i in range(len(predictions3)):\n",
        "    if predictions3[i] > 0.5:\n",
        "        predictions3[i] = 1\n",
        "    else:\n",
        "        predictions3[i] = 0\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(labels, predictions3)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "Ri1iNonC5oCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model4"
      ],
      "metadata": {
        "id": "VHJoIN8KGXXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=200, output_dim=128, mask_zero=True),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Compile the model\n",
        "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history4 = model1.fit(padded_sequences, labels, epochs=10, validation_split=0.2)\n",
        "print(history4.history)"
      ],
      "metadata": {
        "id": "bZ5c18kZGkJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model4.save('model_4.keras')\n",
        "# Load the model\n",
        "model4 = tf.keras.models.load_model('model_4.keras')\n",
        "# Plot accuracy\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history4.history['accuracy']) + 1), history4.history['accuracy'])\n",
        "plt.plot(np.arange(1, len(history4.history['val_accuracy']) + 1), history4.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history4.history['accuracy']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(history4.history['loss']) + 1), history4.history['loss'])\n",
        "plt.plot(np.arange(1, len(history4.history['val_loss']) + 1), history4.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(history3.history['loss']) + 1, 1))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Yw9CnppGrmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions4 = model.predict(padded_sequences)\n",
        "\n",
        "# Convert the predictions to binary values\n",
        "for i in range(len(predictions4)):\n",
        "    if predictions4[i] > 0.5:\n",
        "        predictions4[i] = 1\n",
        "    else:\n",
        "        predictions4[i] = 0\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(labels, predictions4)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "U8-i8a7cG2kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rQEVAAQ-5Vs4"
      }
    }
  ]
}
